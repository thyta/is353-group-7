{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2259cb-e97e-40cc-8c35-b4e35dcfbd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# chia dữ liệu\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tiền xử lý dữ liệu encode, scaler các thứ\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# các thông số đánh giá mô hình\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf8d306-0620-40ae-9252-95f54201e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_excel(\"..\\\\store\\\\fact.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b6dbdd-af2c-47cc-8f9a-da928c2ee2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chenhlech_khoahoc'] = df['khoahoc'] - df['khoahoc_chuan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f253e0d5-d84e-4b18-a9e1-d0bb70155b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mssv', 'xeploai', 'namsinh', 'noisinh', 'gioitinh', 'khoa', 'hedt',\n",
       "       'khoahoc', 'diem_tt', 'dtbhk_hk_1', 'dtbhk_hk_2', 'dtbhk_hk_3',\n",
       "       'dtbhk_hk_4', 'dtbhk_hk_5', 'sotchk_hk_1', 'sotchk_hk_2', 'sotchk_hk_3',\n",
       "       'sotchk_hk_4', 'sotchk_hk_5', 'drl_hk_1', 'drl_hk_2', 'drl_hk_3',\n",
       "       'drl_hk_4', 'drl_hk_5', 'khoahoc_chuan', 'chenhlech_khoahoc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4baf5c03-9ceb-4ec6-a6b5-6146fd823300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chenhlech_khoahoc\n",
       "0     1623\n",
       "1      126\n",
       "2       10\n",
       "3        5\n",
       "4        4\n",
       "6        1\n",
       "11       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['chenhlech_khoahoc'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b711f8-1def-41ae-8e7a-0197955a0190",
   "metadata": {},
   "source": [
    "# Định nghĩa hàm để đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b27bd3c-8878-4b66-89e5-6754d71cbcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo results để lưu các thông số đánh giá mô hình\n",
    "results_df = pd.DataFrame(columns=[\"Model\", \"Epochs\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a532375-cc87-4271-98c6-d32f93d210b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_model(name_model, model, X_test, y_test):\n",
    "    global results_df\n",
    "    \n",
    "    # Dự đoán từ mô hình\n",
    "    y_pred = model.predict(X_test)\n",
    "    if len(y_pred.shape) > 1:  # Trường hợp output là xác suất (probability)\n",
    "        y_pred = y_pred.argmax(axis=1)  # Chọn lớp có xác suất cao nhất\n",
    "    \n",
    "    # Tính các chỉ số đánh giá\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')  # Sử dụng weighted nếu có nhiều lớp\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Lưu kết quả vào DataFrame\n",
    "    new_result = pd.DataFrame({\n",
    "        \"Model\": [name_model],\n",
    "        \"Epochs\": [epochs],\n",
    "        \"Accuracy\": [accuracy],\n",
    "        \"Precision\": [precision],\n",
    "        \"Recall\": [recall],\n",
    "        \"F1_score\": [f1],\n",
    "    })\n",
    "    \n",
    "    results_df = pd.concat([results_df, new_result], ignore_index=True)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b2aa687-5b1c-4fea-9e8f-767e81181072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_model_cnn_2_inputs(name_model, model, X_test_seq, X_test_cat, y_test):\n",
    "    global results_df\n",
    "    \n",
    "    # Dự đoán từ mô hình (CNN với 2 đầu vào)\n",
    "    y_pred = model.predict([X_test_seq, X_test_cat])\n",
    "    \n",
    "    if len(y_pred.shape) > 1:  # Trường hợp output là xác suất (probability)\n",
    "        y_pred = y_pred.argmax(axis=1)  # Chọn lớp có xác suất cao nhất\n",
    "    \n",
    "    # Tính các chỉ số đánh giá\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')  # Sử dụng weighted nếu có nhiều lớp\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Lưu kết quả vào DataFrame\n",
    "    new_result = pd.DataFrame({\n",
    "        \"Model\": [name_model],\n",
    "        \"Epochs\": [epochs],\n",
    "        \"Accuracy\": [accuracy],\n",
    "        \"Precision\": [precision],\n",
    "        \"Recall\": [recall],\n",
    "        \"F1_score\": [f1],\n",
    "    })\n",
    "    \n",
    "    # Cập nhật kết quả vào DataFrame global\n",
    "    results_df = pd.concat([results_df, new_result], ignore_index=True)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b14709b3-2ce4-42b2-8ed5-c4a4f6b94faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['mssv', 'namsinh', 'khoahoc'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b8cdc5-8f82-4b74-8282-d8b90bc057e0",
   "metadata": {},
   "source": [
    "# MLP (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "170290ad-8d98-4dfc-bb61-6d62f58334a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda 3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding cho dữ liệu phân loại\n",
    "mlp_categorical_cols = [\"noisinh\", \"gioitinh\", \"khoa\", \"hedt\", \"chenhlech_khoahoc\", \"diem_tt\"]\n",
    "mlp_encoder = OneHotEncoder()\n",
    "mlp_encoded_features = mlp_encoder.fit_transform(df[mlp_categorical_cols]).toarray()\n",
    "\n",
    "# Chuẩn hóa dữ liệu số\n",
    "mlp_numerical_cols = [col for col in df.columns if \"dtbhk_hk_\" in col or \"sotchk_hk_\" in col or \"drl_hk_\" in col]\n",
    "mlp_scaler = MinMaxScaler()\n",
    "mlp_scaled_features = mlp_scaler.fit_transform(df[mlp_numerical_cols])\n",
    "\n",
    "# Kết hợp các đặc trưng\n",
    "mlp_X = np.hstack([mlp_scaled_features, mlp_encoded_features])\n",
    "# Chuyển xếp loại thành nhãn số\n",
    "mlp_y = df[\"xeploai\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Chia dữ liệu\n",
    "mlp_X_train, mlp_X_temp, mlp_y_train, mlp_y_temp = train_test_split(mlp_X, mlp_y, test_size=0.2, random_state=42)\n",
    "mlp_X_val, mlp_X_test, mlp_y_val, mlp_y_test = train_test_split(mlp_X_temp, mlp_y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# MLP Model\n",
    "mlp_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(mlp_X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(len(np.unique(mlp_y)), activation='softmax')\n",
    "])\n",
    "\n",
    "mlp_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb1b614-96b2-4815-bf3a-65c0c73132d9",
   "metadata": {},
   "source": [
    "# LSTM (Long Short-Term Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1432aa9b-13e0-4c02-b039-4fba7b717069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda 3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Dữ liệu chuỗi (chỉ chọn các cột tuần tự)\n",
    "lstm_seq_features = [f\"dtbhk_hk_{i}\" for i in range(1, 6)] + [f\"sotchk_hk_{i}\" for i in range(1, 6)] + [f\"drl_hk_{i}\" for i in range(1, 6)]\n",
    "# Đổi sang numpy cho phù hợp với LSTM model\n",
    "lstm_df_numpy = df[lstm_seq_features].values\n",
    "# Reshape: (samples, timesteps, features)\n",
    "lstm_sequence_data = lstm_df_numpy.reshape(lstm_df_numpy.shape[0], 5, -1)\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "lstm_scaler = MinMaxScaler()\n",
    "lstm_sequence_data = lstm_sequence_data.reshape(-1, lstm_sequence_data.shape[-1])\n",
    "lstm_sequence_data = lstm_scaler.fit_transform(lstm_sequence_data)\n",
    "lstm_sequence_data = lstm_sequence_data.reshape(-1, 5, len(lstm_seq_features) // 5)\n",
    "\n",
    "# Dữ liệu label\n",
    "lstm_y = df[\"xeploai\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Chia dữ liệu\n",
    "lstm_X_train, lstm_X_temp, lstm_y_train, lstm_y_temp = train_test_split(lstm_sequence_data, lstm_y, test_size=0.2, random_state=42)\n",
    "lstm_X_val, lstm_X_test, lstm_y_val, lstm_y_test = train_test_split(lstm_X_temp, lstm_y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# LSTM Model\n",
    "lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=(5, len(lstm_seq_features) // 5), return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(len(np.unique(lstm_y)), activation='softmax')\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c9824-e55c-462f-a331-28fb646552dd",
   "metadata": {},
   "source": [
    "# CNN (Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7786c2b6-e80f-490c-ad0b-bcf4289aea8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda 3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Dữ liệu chuỗi (chỉ chọn các cột tuần tự)\n",
    "cnn_seq_features = [f\"dtbhk_hk_{i}\" for i in range(1, 6)] + [f\"sotchk_hk_{i}\" for i in range(1, 6)] + [f\"drl_hk_{i}\" for i in range(1, 6)]\n",
    "cnn_sequence_data = df[cnn_seq_features].values\n",
    "cnn_sequence_data = cnn_sequence_data.reshape(cnn_sequence_data.shape[0], 5, -1)\n",
    "\n",
    "# Chuẩn hóa\n",
    "cnn_scaler = MinMaxScaler()\n",
    "cnn_sequence_data = cnn_sequence_data.reshape(-1, cnn_sequence_data.shape[-1])\n",
    "cnn_sequence_data = cnn_scaler.fit_transform(cnn_sequence_data)\n",
    "cnn_sequence_data = cnn_sequence_data.reshape(-1, 5, len(cnn_seq_features) // 5)\n",
    "\n",
    "# Dữ liệu label\n",
    "cnn_y = df[\"xeploai\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Chia dữ liệu\n",
    "cnn_X_train, cnn_X_temp, cnn_y_train, cnn_y_temp = train_test_split(cnn_sequence_data, cnn_y, test_size=0.2, random_state=42)\n",
    "cnn_X_val, cnn_X_test, cnn_y_val, cnn_y_test = train_test_split(cnn_X_temp, cnn_y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# CNN Model\n",
    "cnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(32, kernel_size=2, activation='relu', input_shape=(5, len(cnn_seq_features) // 5)),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=2, activation='relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(len(np.unique(cnn_y)), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d4080-c692-4bae-9a9f-6cc4dbe17a4a",
   "metadata": {},
   "source": [
    "# LSTM 2 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9c3cfde-88fc-409a-bd50-17cf735829cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trích xuất các đặc trưng\n",
    "lstm_2_inputs_categorical_features = [\"noisinh\", \"gioitinh\", \"khoa\", \"hedt\", \"chenhlech_khoahoc\", \"diem_tt\"]\n",
    "lstm_2_inputs_sequence_features = [f\"dtbhk_hk_{i}\" for i in range(1, 6)] + \\\n",
    "                                   [f\"sotchk_hk_{i}\" for i in range(1, 6)] + \\\n",
    "                                   [f\"drl_hk_{i}\" for i in range(1, 6)]\n",
    "\n",
    "# Xử lý các đặc trưng categorical\n",
    "lstm_2_inputs_cat_data = df[lstm_2_inputs_categorical_features].copy()\n",
    "for col in lstm_2_inputs_categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    lstm_2_inputs_cat_data[col] = le.fit_transform(lstm_2_inputs_cat_data[col])\n",
    "\n",
    "# Chuẩn hóa dữ liệu categorical\n",
    "lstm_2_inputs_cat_data = MinMaxScaler().fit_transform(lstm_2_inputs_cat_data)\n",
    "\n",
    "# Xử lý dữ liệu sequence\n",
    "lstm_2_inputs_sequence_data = df[lstm_2_inputs_sequence_features].values\n",
    "lstm_2_inputs_sequence_data = lstm_2_inputs_sequence_data.reshape(lstm_2_inputs_sequence_data.shape[0], 5, -1)\n",
    "lstm_2_inputs_scaler = MinMaxScaler()\n",
    "lstm_2_inputs_sequence_data = lstm_2_inputs_sequence_data.reshape(-1, lstm_2_inputs_sequence_data.shape[-1])\n",
    "lstm_2_inputs_sequence_data = lstm_2_inputs_scaler.fit_transform(lstm_2_inputs_sequence_data)\n",
    "lstm_2_inputs_sequence_data = lstm_2_inputs_sequence_data.reshape(-1, 5, len(lstm_2_inputs_sequence_features) // 5)\n",
    "\n",
    "# Chia dữ liệu\n",
    "lstm_2_inputs_y = df[\"xeploai\"].astype(\"category\").cat.codes\n",
    "lstm_2_inputs_X_train_seq, lstm_2_inputs_X_temp_seq, lstm_2_inputs_y_train, lstm_2_inputs_y_temp = train_test_split(\n",
    "    lstm_2_inputs_sequence_data, lstm_2_inputs_y, test_size=0.2, random_state=42)\n",
    "lstm_2_inputs_X_train_cat, lstm_2_inputs_X_temp_cat = train_test_split(\n",
    "    lstm_2_inputs_cat_data, test_size=0.2, random_state=42)\n",
    "lstm_2_inputs_X_val_seq, lstm_2_inputs_X_test_seq, lstm_2_inputs_y_val, lstm_2_inputs_y_test = train_test_split(\n",
    "    lstm_2_inputs_X_temp_seq, lstm_2_inputs_y_temp, test_size=0.5, random_state=42)\n",
    "lstm_2_inputs_X_val_cat, lstm_2_inputs_X_test_cat = train_test_split(\n",
    "    lstm_2_inputs_X_temp_cat, test_size=0.5, random_state=42)\n",
    "\n",
    "# LSTM Model với 2 đầu vào\n",
    "lstm_2_inputs_sequence_input = tf.keras.Input(shape=(5, len(lstm_2_inputs_sequence_features) // 5))\n",
    "lstm_2_inputs_x_seq = tf.keras.layers.LSTM(64, return_sequences=True)(lstm_2_inputs_sequence_input)\n",
    "lstm_2_inputs_x_seq = tf.keras.layers.Dropout(0.3)(lstm_2_inputs_x_seq)\n",
    "lstm_2_inputs_x_seq = tf.keras.layers.LSTM(32)(lstm_2_inputs_x_seq)\n",
    "lstm_2_inputs_x_seq = tf.keras.layers.Dropout(0.3)(lstm_2_inputs_x_seq)\n",
    "\n",
    "# Nhánh xử lý dữ liệu categorical\n",
    "lstm_2_inputs_categorical_input = tf.keras.Input(shape=(lstm_2_inputs_cat_data.shape[1],))\n",
    "lstm_2_inputs_x_cat = tf.keras.layers.Dense(64, activation='relu')(lstm_2_inputs_categorical_input)\n",
    "lstm_2_inputs_x_cat = tf.keras.layers.Dropout(0.3)(lstm_2_inputs_x_cat)\n",
    "\n",
    "# Kết hợp cả hai nhánh\n",
    "lstm_2_inputs_combined = tf.keras.layers.concatenate([lstm_2_inputs_x_seq, lstm_2_inputs_x_cat])\n",
    "\n",
    "# Các tầng Dense cuối cùng để dự đoán\n",
    "lstm_2_inputs_x = tf.keras.layers.Dense(64, activation='relu')(lstm_2_inputs_combined)\n",
    "lstm_2_inputs_x = tf.keras.layers.Dropout(0.3)(lstm_2_inputs_x)\n",
    "lstm_2_inputs_output = tf.keras.layers.Dense(len(np.unique(lstm_2_inputs_y)), activation='softmax')(lstm_2_inputs_x)\n",
    "\n",
    "# Compile mô hình\n",
    "lstm_2_inputs_model = tf.keras.Model(\n",
    "    inputs=[lstm_2_inputs_sequence_input, lstm_2_inputs_categorical_input], \n",
    "    outputs=lstm_2_inputs_output)\n",
    "lstm_2_inputs_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d8a510-6b0a-4c9f-8b59-ee4abd860acb",
   "metadata": {},
   "source": [
    "# CNN 2 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "049440d3-b8b0-4cf5-aff1-1cbb38729e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trích xuất các đặc trưng\n",
    "cnn_2_inputs_categorical_features = [\"noisinh\", \"gioitinh\", \"khoa\", \"hedt\", \"chenhlech_khoahoc\", \"diem_tt\"]\n",
    "cnn_2_inputs_sequence_features = [f\"dtbhk_hk_{i}\" for i in range(1, 6)] + \\\n",
    "                                  [f\"sotchk_hk_{i}\" for i in range(1, 6)] + \\\n",
    "                                  [f\"drl_hk_{i}\" for i in range(1, 6)]\n",
    "\n",
    "# Xử lý các đặc trưng categorical\n",
    "cnn_2_inputs_cat_data = df[cnn_2_inputs_categorical_features].copy()\n",
    "cnn_2_inputs_label_encoders = {}\n",
    "for col in cnn_2_inputs_categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    cnn_2_inputs_cat_data[col] = le.fit_transform(cnn_2_inputs_cat_data[col])\n",
    "    cnn_2_inputs_label_encoders[col] = le\n",
    "\n",
    "# Chuẩn hóa categorical data\n",
    "cnn_2_inputs_cat_data = MinMaxScaler().fit_transform(cnn_2_inputs_cat_data)\n",
    "\n",
    "# Huấn luyện scaler_cat\n",
    "cnn_2_inputs_scaler_cat = MinMaxScaler()\n",
    "cnn_2_inputs_scaler_cat.fit(cnn_2_inputs_cat_data)\n",
    "\n",
    "cnn_2_inputs_sequence_data = df[cnn_2_inputs_sequence_features].values\n",
    "cnn_2_inputs_sequence_data = cnn_2_inputs_sequence_data.reshape(\n",
    "    cnn_2_inputs_sequence_data.shape[0], 5, -1)  # (n_samples, 5, n_features_per_step)\n",
    "\n",
    "# Chuyển sequence_data thành 2D để fit MinMaxScaler\n",
    "cnn_2_inputs_scaler_seq = MinMaxScaler()\n",
    "cnn_2_inputs_sequence_data_2d = cnn_2_inputs_sequence_data.reshape(\n",
    "    -1, cnn_2_inputs_sequence_data.shape[-1])  # (n_samples * 5, n_features_per_step)\n",
    "\n",
    "# Huấn luyện scaler\n",
    "cnn_2_inputs_scaler_seq.fit(cnn_2_inputs_sequence_data_2d)\n",
    "\n",
    "# Chuẩn hóa sequence_data và chuyển lại về 3D\n",
    "cnn_2_inputs_sequence_data_2d_scaled = cnn_2_inputs_scaler_seq.transform(\n",
    "    cnn_2_inputs_sequence_data_2d)  # Chuẩn hóa dữ liệu 2D\n",
    "cnn_2_inputs_sequence_data_scaled = cnn_2_inputs_sequence_data_2d_scaled.reshape(\n",
    "    -1, 5, cnn_2_inputs_sequence_data.shape[-1])  # Chuyển về 3D\n",
    "\n",
    "# Chia dữ liệu\n",
    "cnn_2_inputs_y = df[\"xeploai\"].astype(\"category\").cat.codes\n",
    "cnn_2_inputs_X_train_seq, cnn_2_inputs_X_temp_seq, cnn_2_inputs_y_train, cnn_2_inputs_y_temp = train_test_split(\n",
    "    cnn_2_inputs_sequence_data_scaled, cnn_2_inputs_y, test_size=0.2, random_state=42)\n",
    "cnn_2_inputs_X_train_cat, cnn_2_inputs_X_temp_cat = train_test_split(\n",
    "    cnn_2_inputs_cat_data, test_size=0.2, random_state=42)\n",
    "cnn_2_inputs_X_val_seq, cnn_2_inputs_X_test_seq, cnn_2_inputs_y_val, cnn_2_inputs_y_test = train_test_split(\n",
    "    cnn_2_inputs_X_temp_seq, cnn_2_inputs_y_temp, test_size=0.5, random_state=42)\n",
    "cnn_2_inputs_X_val_cat, cnn_2_inputs_X_test_cat = train_test_split(\n",
    "    cnn_2_inputs_X_temp_cat, test_size=0.5, random_state=42)\n",
    "\n",
    "# Nhánh xử lý sequence\n",
    "cnn_2_inputs_sequence_input = tf.keras.Input(shape=(5, len(cnn_2_inputs_sequence_features) // 5))\n",
    "cnn_2_inputs_x_seq = tf.keras.layers.Conv1D(32, kernel_size=2, activation='relu')(cnn_2_inputs_sequence_input)\n",
    "cnn_2_inputs_x_seq = tf.keras.layers.MaxPooling1D(pool_size=2)(cnn_2_inputs_x_seq)\n",
    "cnn_2_inputs_x_seq = tf.keras.layers.Conv1D(64, kernel_size=2, activation='relu')(cnn_2_inputs_x_seq)\n",
    "cnn_2_inputs_x_seq = tf.keras.layers.GlobalMaxPooling1D()(cnn_2_inputs_x_seq)\n",
    "\n",
    "# Nhánh xử lý categorical\n",
    "cnn_2_inputs_categorical_input = tf.keras.Input(shape=(cnn_2_inputs_cat_data.shape[1],))\n",
    "cnn_2_inputs_x_cat = tf.keras.layers.Dense(64, activation='relu')(cnn_2_inputs_categorical_input)\n",
    "\n",
    "# Kết hợp các nhánh\n",
    "cnn_2_inputs_combined = tf.keras.layers.concatenate([cnn_2_inputs_x_seq, cnn_2_inputs_x_cat])\n",
    "cnn_2_inputs_x = tf.keras.layers.Dense(64, activation='relu')(cnn_2_inputs_combined)\n",
    "cnn_2_inputs_x = tf.keras.layers.Dropout(0.3)(cnn_2_inputs_x)\n",
    "cnn_2_inputs_output = tf.keras.layers.Dense(len(np.unique(cnn_2_inputs_y)), activation='softmax')(cnn_2_inputs_x)\n",
    "\n",
    "# Compile mô hình\n",
    "cnn_2_inputs_model = tf.keras.Model(inputs=[cnn_2_inputs_sequence_input, cnn_2_inputs_categorical_input], \n",
    "                                    outputs=cnn_2_inputs_output)\n",
    "cnn_2_inputs_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250bff2a-c957-4308-9889-474a73df16d1",
   "metadata": {},
   "source": [
    "# chạy mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b981e38c-971e-48ef-b254-3ec8844ef220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6497 - loss: 0.8394 - val_accuracy: 0.6780 - val_loss: 0.7160\n",
      "Epoch 2/2\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6711 - loss: 0.7668 - val_accuracy: 0.6836 - val_loss: 0.6693\n",
      "Epoch 1/2\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5957 - loss: 0.9664 - val_accuracy: 0.6441 - val_loss: 0.9061\n",
      "Epoch 2/2\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6181 - loss: 0.9516 - val_accuracy: 0.6441 - val_loss: 0.8965\n",
      "Epoch 1/2\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6081 - loss: 0.9774 - val_accuracy: 0.6441 - val_loss: 0.8977\n",
      "Epoch 2/2\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6054 - loss: 0.9732 - val_accuracy: 0.6441 - val_loss: 0.9014\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda 3\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_44', 'keras_tensor_49']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.4335 - loss: 1.2678 - val_accuracy: 0.6441 - val_loss: 0.9317\n",
      "Epoch 2/2\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6093 - loss: 0.9890 - val_accuracy: 0.6441 - val_loss: 0.8981\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda 3\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_56', 'keras_tensor_61']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5594 - loss: 1.1841 - val_accuracy: 0.6441 - val_loss: 0.9158\n",
      "Epoch 2/2\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5983 - loss: 1.0002 - val_accuracy: 0.6441 - val_loss: 0.8934\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "# Huấn luyện các mô hình\n",
    "mlp_history = mlp_model.fit(mlp_X_train, mlp_y_train, validation_data=(mlp_X_val, mlp_y_val), epochs=epochs, batch_size=32)\n",
    "evaluate_and_save_model(\"MLP - Multi-Layer Perceptron \", mlp_model, mlp_X_test, mlp_y_test)\n",
    "\n",
    "lstm_history = lstm_model.fit(lstm_X_train, lstm_y_train, validation_data=(lstm_X_val, lstm_y_val), epochs=epochs, batch_size=32)\n",
    "evaluate_and_save_model(\"LSTM (Long Short-Term Memory)\", lstm_model, lstm_X_test, lstm_y_test)\n",
    "\n",
    "cnn_history = cnn_model.fit(cnn_X_train, cnn_y_train, validation_data=(cnn_X_val, cnn_y_val), epochs=epochs, batch_size=32)\n",
    "evaluate_and_save_model(\"CNN (Convolutional Neural Network)\", cnn_model, cnn_X_test, cnn_y_test)\n",
    "\n",
    "lstm_2_inputs_history = lstm_2_inputs_model.fit([lstm_2_inputs_X_train_seq, lstm_2_inputs_X_train_cat], lstm_2_inputs_y_train, validation_data=([lstm_2_inputs_X_val_seq, lstm_2_inputs_X_val_cat], lstm_2_inputs_y_val), epochs=epochs, batch_size=32)\n",
    "evaluate_and_save_model_cnn_2_inputs(\"LSTM (Long Short-Term Memory) 2 Inputs\", lstm_2_inputs_model, lstm_2_inputs_X_test_seq, lstm_2_inputs_X_test_cat, lstm_2_inputs_y_test)\n",
    "\n",
    "cnn_2_inputs_history = cnn_2_inputs_model.fit([cnn_2_inputs_X_train_seq, cnn_2_inputs_X_train_cat], cnn_2_inputs_y_train, validation_data=([cnn_2_inputs_X_val_seq, cnn_2_inputs_X_val_cat], cnn_2_inputs_y_val), epochs=epochs, batch_size=32)\n",
    "evaluate_and_save_model_cnn_2_inputs(\"CNN (Convolutional Neural Network)\", cnn_2_inputs_model, cnn_2_inputs_X_test_seq, cnn_2_inputs_X_test_cat, cnn_2_inputs_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f1abc-e5be-4688-b984-b53b52a627d6",
   "metadata": {},
   "source": [
    "# so sánh các mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c1f9626-3c20-402b-937a-73e3050cf998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, Epochs, Accuracy, Precision, Recall, F1_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7f574c-77f7-485a-82b8-fc4042a11e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
