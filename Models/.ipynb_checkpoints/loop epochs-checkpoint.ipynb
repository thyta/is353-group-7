{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423a8e7b-5aa2-4a9c-a2c7-fdbf9ff724ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# chia dữ liệu\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tiền xử lý dữ liệu encode, scaler các thứ\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# các thông số đánh giá mô hình\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "630a7235-7767-439e-874d-efc5e65e6da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\anhthy\\AppData\\Local\\Temp\\ipykernel_43184\\3586620629.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df =  pd.read_excel(\"..\\store\\\\fact.xlsx\")\n"
     ]
    }
   ],
   "source": [
    "df =  pd.read_excel(\"..\\store\\\\fact.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fa21284-4d7f-4a5f-af24-b662815dab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo results để lưu các thông số đánh giá mô hình\n",
    "results_df = pd.DataFrame(columns=[\"Model\", \"Epochs\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_score\"])\n",
    "\n",
    "def evaluate_and_save_model(name_model, epochs, model, X_test, y_test):\n",
    "    global results_df\n",
    "    \n",
    "    # Dự đoán từ mô hình\n",
    "    y_pred = model.predict(X_test)\n",
    "    if len(y_pred.shape) > 1:  # Trường hợp output là xác suất (probability)\n",
    "        y_pred = y_pred.argmax(axis=1)  # Chọn lớp có xác suất cao nhất\n",
    "    \n",
    "    # Tính các chỉ số đánh giá\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')  # Sử dụng weighted nếu có nhiều lớp\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Lưu kết quả vào DataFrame\n",
    "    new_result = pd.DataFrame({\n",
    "        \"Epochs\": epochs,\n",
    "        \"Model\": [name_model],\n",
    "        \"Accuracy\": [accuracy],\n",
    "        \"Precision\": [precision],\n",
    "        \"Recall\": [recall],\n",
    "        \"F1_score\": [f1],\n",
    "    })\n",
    "    \n",
    "    results_df = pd.concat([results_df, new_result], ignore_index=True)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d86a9ae1-38cc-455c-9a9d-80f84607a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['mssv', 'khoahoc_chuan'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a0ff07-fa36-4638-a936-d4c1f71b6389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_train_mlp(epochs, df=df):\n",
    "    # Define categorical and numerical columns\n",
    "    categorical_cols = [\"gioitinh\", \"noisinh\", \"khoa\", \"hedt\"]\n",
    "    numerical_cols = [\"diem_tt\"] + [col for col in df.columns if \"dtbhk_hk_\" in col or \"sotchk_hk_\" in col or \"drl_hk_\" in col]\n",
    "    \n",
    "    # One-Hot Encoding for categorical data\n",
    "    encoder = OneHotEncoder()\n",
    "    encoded_features = encoder.fit_transform(df[categorical_cols]).toarray()\n",
    "\n",
    "    # Normalize numerical data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "    # Combine features\n",
    "    X = np.hstack([scaled_features, encoded_features])\n",
    "    \n",
    "    # Convert target variable to numerical labels\n",
    "    y = df[\"xeploai\"].astype(\"category\").cat.codes \n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Define MLP model\n",
    "    mlp_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(len(np.unique(y)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    mlp_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    mlp_history = mlp_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=32)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    evaluate_and_save_model(\"MLP (Multi-Layer Perceptron) \" + str(epochs), epochs, mlp_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee189a6-309c-4b36-b2d9-5b50805eba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_train_lstm(epochs, df=df):\n",
    "    # Define sequential features\n",
    "    seq_features = [f\"dtbhk_hk_{i}\" for i in range(1, 6)] + \\\n",
    "                   [f\"sotchk_hk_{i}\" for i in range(1, 6)] + \\\n",
    "                   [f\"drl_hk_{i}\" for i in range(1, 6)]\n",
    "    \n",
    "    # Convert DataFrame to NumPy array\n",
    "    df_numpy = df[seq_features].values\n",
    "    \n",
    "    # Reshape: (samples, timesteps, features)\n",
    "    sequence_data = df_numpy.reshape(df_numpy.shape[0], 5, -1)\n",
    "    \n",
    "    # Normalize data\n",
    "    scaler = MinMaxScaler()\n",
    "    sequence_data = sequence_data.reshape(-1, sequence_data.shape[-1])\n",
    "    sequence_data = scaler.fit_transform(sequence_data)\n",
    "    sequence_data = sequence_data.reshape(-1, 5, len(seq_features) // 5)\n",
    "\n",
    "    # Prepare labels\n",
    "    y = df[\"xeploai\"].astype(\"category\").cat.codes\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(sequence_data, y, test_size=0.2, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Define LSTM model\n",
    "    lstm_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(64, input_shape=(5, len(seq_features) // 5), return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.LSTM(32),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(len(np.unique(y)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    lstm_history = lstm_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=32)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    evaluate_and_save_model(\"LSTM (Long Short-Term Memory) \"+ str(epochs), epochs, lstm_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c476d077-a97f-48d3-8af7-44a85b3e2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_train_cnn(epochs, df=df):\n",
    "    # Define sequential features\n",
    "    seq_features = [f\"dtbhk_hk_{i}\" for i in range(1, 6)] + \\\n",
    "                   [f\"sotchk_hk_{i}\" for i in range(1, 6)] + \\\n",
    "                   [f\"drl_hk_{i}\" for i in range(1, 6)]\n",
    "    \n",
    "    # Convert DataFrame to NumPy array\n",
    "    sequence_data = df[seq_features].values\n",
    "    \n",
    "    # Reshape: (samples, timesteps, features)\n",
    "    sequence_data = sequence_data.reshape(sequence_data.shape[0], 5, -1)\n",
    "    \n",
    "    # Normalize data\n",
    "    scaler = MinMaxScaler()\n",
    "    sequence_data = sequence_data.reshape(-1, sequence_data.shape[-1])\n",
    "    sequence_data = scaler.fit_transform(sequence_data)\n",
    "    sequence_data = sequence_data.reshape(-1, 5, len(seq_features) // 5)\n",
    "\n",
    "    # Prepare labels\n",
    "    y = df[\"xeploai\"].astype(\"category\").cat.codes\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(sequence_data, y, test_size=0.2, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Define CNN model\n",
    "    cnn_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(32, kernel_size=2, activation='relu', input_shape=(5, len(seq_features) // 5)),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Conv1D(64, kernel_size=2, activation='relu'),\n",
    "        tf.keras.layers.GlobalMaxPooling1D(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(len(np.unique(y)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    cnn_history = cnn_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=32)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    evaluate_and_save_model(\"CNN (Convolutional Neural Network) \" + str(epochs), epochs, cnn_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaf56fcb-b97b-4ac6-b7b9-fac633dedcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_models_with_epochs(df):\n",
    "    results = {}\n",
    "    # Tạo danh sách epoch từ 5 đến 200, cách nhau 5\n",
    "    epoch_list = list(range(5, 151, 20))  # từ 5 đến 150, cách nhau 10\n",
    "\n",
    "    # Lặp qua mỗi giá trị epoch\n",
    "    for epochs in epoch_list:\n",
    "        print(f\"Training models for {epochs} epochs...\")\n",
    "        results[epochs] = {\n",
    "            'MLP': preprocess_and_train_mlp(epochs),\n",
    "            'LSTM': preprocess_and_train_lstm(epochs),\n",
    "            'CNN': preprocess_and_train_cnn(epochs)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c045fea-da02-43f7-862b-15a7fc8580c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models for 5 epochs...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda 3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5488 - loss: 1.1304 - val_accuracy: 0.6441 - val_loss: 0.8552\n",
      "Epoch 2/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6161 - loss: 0.9237 - val_accuracy: 0.6497 - val_loss: 0.7962\n",
      "Epoch 3/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6420 - loss: 0.8742 - val_accuracy: 0.6780 - val_loss: 0.7539\n",
      "Epoch 4/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6659 - loss: 0.8053 - val_accuracy: 0.7006 - val_loss: 0.7371\n",
      "Epoch 5/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6659 - loss: 0.7663 - val_accuracy: 0.6780 - val_loss: 0.6874\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda 3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\anhthy\\AppData\\Local\\Temp\\ipykernel_43184\\3439423200.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, new_result], ignore_index=True)\n",
      "E:\\Anaconda 3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4430 - loss: 1.3070 - val_accuracy: 0.6441 - val_loss: 0.9511\n",
      "Epoch 2/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5998 - loss: 1.0259 - val_accuracy: 0.6441 - val_loss: 0.9041\n",
      "Epoch 3/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6163 - loss: 0.9650 - val_accuracy: 0.6441 - val_loss: 0.8982\n",
      "Epoch 4/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6238 - loss: 0.9459 - val_accuracy: 0.6441 - val_loss: 0.8998\n",
      "Epoch 5/5\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6211 - loss: 0.9416 - val_accuracy: 0.6441 - val_loss: 0.8911\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 391ms/step"
     ]
    }
   ],
   "source": [
    "run_all_models_with_epochs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cecc47b-a35d-4c44-b94b-d841f9ff38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
